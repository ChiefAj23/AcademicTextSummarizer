# ğŸ“š Academic Text Summarizer
A lightweight, AI-powered web application that generates concise and coherent summaries of academic texts, research papers, articles, and technical documentation. Built using Hugging Face Transformers and Gradio, this tool is designed to assist graduate students, researchers, and knowledge workers by simplifying the summarization process.

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![Transformers](https://img.shields.io/badge/ğŸ¤—-Transformers-orange)
![Gradio](https://img.shields.io/badge/Gradio-UI-lightgrey?logo=gradio)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)

---

## Problem Statement
AsÂ a graduate researcher, IÂ must regularly read and summarize voluminous research papers and academicÂ journals. ThisÂ isÂ aÂ time-consuming and mentallyÂ exhausting process. ThisÂ routineÂ processÂ actsÂ as a hurdle toÂ productivity and slowsÂ downÂ theÂ rateÂ of literature review andÂ synthesis ofÂ knowledge.Â To address this issue, IÂ designedÂ an AI-powered summarization tool thatÂ employsÂ theÂ latestÂ natural language processing techniques toÂ produceÂ concise summaries from lengthy academicÂ documents. This toolÂ willÂ beÂ helpfulÂ forÂ students,Â scholars, and professionals by automatically summarizing, saving time, and enhancing comprehension.

---

## ğŸš€ Features

- ğŸ§‘â€ğŸ§¬ **Abstractive Summarization** using `distilbart-cnn-12-6` (Hugging Face)
- âš™ï¸ Built with **Gradio** for an interactive, browser-based UI
- ğŸ’¾ Supports **local inference** for offline use
- ğŸ’¬ Simple and intuitive user experience
- ğŸ‘¨â€ğŸ“ Designed specifically for students, researchers, and educators

---

## ğŸ§  Model Information

This app uses the `sshleifer/distilbart-cnn-12-6` model from Hugging Face, which is a distilled version of Facebook's BART model fine-tuned on the CNN/DailyMail dataset for summarization tasks.

### ğŸ“¥ Downloading the Model Manually (Optional)
If you prefer not to download the model at runtime, you can manually download it and use it locally.

#### Step 1: Download the model
```bash
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model_name = "sshleifer/distilbart-cnn-12-6"
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

model.save_pretrained("./models/distilbart-cnn-12-6")
tokenizer.save_pretrained("./models/distilbart-cnn-12-6")
```

#### Step 2: Update app code to use local path
```python
model_path = "./models/distilbart-cnn-12-6"
text_summary = pipeline("summarization", model=model_path, tokenizer=model_path)
```

This enables **offline inference** and faster loading time for repeated use.

---

## ğŸ’  Tech Stack

| Component     | Description                                       |
|---------------|---------------------------------------------------|
| `Python`      | Programming language                              |
| `Hugging Face Transformers` | NLP model loading and inference     |
| `Gradio`      | Web UI for model interaction                      |
| `PyTorch`     | Deep learning backend for transformer inference   |

---

## ğŸ“‚ File Structure

```
ğŸ“ text-summarizer-app/
â”‚
â”œâ”€â”€ app.py                 # Gradio app interface
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ models/                # Local model snapshots (optional)
```

---


## ğŸ“¦ Installation

### 1. Clone the repository

```bash
git clone https://github.com/ChiefAj23/AcademicTextSummarizer.git
cd text-summarizer-app
```

### 2. Set up virtual environment (recommended)

```bash
python -m venv .venv
source .venv/bin/activate   # On Windows: .venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the app

```bash
python app.py
```

---

## ğŸ“¸ UI Preview

> Coming soon...

---

## âœï¸ Author

**Abhijeet Solanki**
If you enjoyed this or have suggestions, feel free to reach out!
Abhijeet Solanki

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

